<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-24T19:57:35+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">NoamZeise</title><subtitle>A collection of programming projects</subtitle><entry><title type="html">Deli-Cat-Essen - Make sandwiches for cats!</title><link href="http://localhost:4000/gamejam/2023/02/20/deli-cat-essen.html" rel="alternate" type="text/html" title="Deli-Cat-Essen - Make sandwiches for cats!" /><published>2023-02-20T00:00:00+00:00</published><updated>2023-02-20T00:00:00+00:00</updated><id>http://localhost:4000/gamejam/2023/02/20/deli-cat-essen</id><content type="html" xml:base="http://localhost:4000/gamejam/2023/02/20/deli-cat-essen.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/3-gcNAaqQVM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>Made with my <a href="https://github.com/NoamZeise/sdl2-rs-game-template">rust game library</a> in 48 hours for <a href="https://www.ducksauce.games/duck-sauce-jam-2023">Duck Sauce Games Jam 2023</a>, where it earned  2nd  place.</p>

<p><a href="https://noamzeise.itch.io/deli-cat-essen">download on itch.io</a></p>

<p><a href="https://github.com/NoamZeise/DSJ2023">view source code on github</a></p>

<h4 id="credits">Credits:</h4>
<ul>
  <li>
    <p><a href="https://gerbzies.itch.io/">Laura King</a> - Art and Game Design</p>
  </li>
  <li>
    <p>Noam Zeise - Programming and Game Design</p>
  </li>
</ul>

<p>You run a deli shop, where you sell sandwiches, but you specialise in fully customisable orders. Customers ask for whatever they please, be that a bread sandwich or a quintuple tomato stack. Your customers are not only particular, they are also quite impatient. If you take too long to fulfill their order, they will take off and give your business a purr review. So make sure to keep them happy!</p>

<p>If you have any ingredients that you don’t want, feed them to the cat on the very left, he’s always hungry!</p>]]></content><author><name></name></author><category term="GameJam" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Bunny Patch - a simulation game about protecting a carrot patch</title><link href="http://localhost:4000/gamejam/2023/02/05/BunnyPatch.html" rel="alternate" type="text/html" title="Bunny Patch - a simulation game about protecting a carrot patch" /><published>2023-02-05T00:00:00+00:00</published><updated>2023-02-05T00:00:00+00:00</updated><id>http://localhost:4000/gamejam/2023/02/05/BunnyPatch</id><content type="html" xml:base="http://localhost:4000/gamejam/2023/02/05/BunnyPatch.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/fmegaXGNcH4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>Protect your carrot patch from encroaching weeds.</p>

<p>Made with my <a href="https://github.com/NoamZeise/sdl2-rs-game-template">rust game library</a> in 48 hours for <a href="https://globalgamejam.org/2023/games/bunnypatch-0">global game jam 2023</a>.</p>

<p>Click next turn to advance time by a few step, and you can watch as the game world changes. When the carrots sparkle, it means they have been harvested and added to your carrot bank in the top right. You can click on the button in the top left to open the shop and buy tiles that interact with the world in some way.</p>

<p><a href="https://noamzeise.itch.io/bunnypatch">download on itch.io</a></p>

<p><a href="https://github.com/NoamZeise/BunnyPatch">view source code on github</a></p>

<h4 id="credits">Credits:</h4>
<ul>
  <li>
    <p><a href="https://gerbzies.itch.io/">Laura King</a> - Art and Game Design</p>
  </li>
  <li>
    <p>Noam Zeise - Programming and Game Design</p>
  </li>
  <li>
    <p><a href="https://youtube.com/channel/UCs75GjfGdtTS-CekMJOGICA">Mick Cooke – MakeFire Music</a> - Music and Sound Effects</p>
  </li>
</ul>

<h2 id="implementation-details">Implementation Details</h2>

<p>I added many new features to my Rust game library since I had last used it for a jam, now it hides 
all of the details of SDL. Controls are also much easier to add, and a lot of unrelated systems that were previously connected have been more seperated (ie render, input, camera, map, etc…).</p>

<p>The Board is implimented as an array of Boxed objects that impliment the ‘Tile’ trait. This trait
defines the behavior of a tile type, what it looks like, how it affects other tiles, and how other tiles affect it. Here is the trait</p>

<pre><code class="language-Rust">pub trait Tile {
    fn tile(&amp;self) -&gt; Tiles {
        Tiles::None
    }

    fn pos(&amp;self) -&gt; (usize, usize);

    fn removed(&amp;mut self) -&gt; bool {
        false
	}

    fn update(&amp;mut self, _map: &amp;mut Tilemap) {}

    fn draw(&amp;self, _cam: &amp;mut Camera) {}

    fn interact(&amp;mut self, _tile:Tiles) {}
}
</code></pre>

<p>When the simulation steps forward, the update function is called on each tile. Each tile can
add a <code class="language-plaintext highlighter-rouge">Choice</code> to the tilemap, which is a request for affecting a certain tile. Each of these
choices are looped through and applied to their targets. The choice has two affects, it can
either cause the target to be replaced, or will cause a change in the state of the target.</p>

<pre><code class="language-Rust"> fn step(&amp;mut self, ui: &amp;mut Ui) {
 
        for t in self.obj_map.iter_mut() {
            t.update(&amp;mut self.board);
        }

        for c in self.board.map_updates.drain(..) {
            if self.obj_map[c.i].tile() == Tiles::Grass {
                    self.set(c);
                } else  {
                    self.obj_map[c.i].interact(c.dst);
                    if self.obj_map[c.i].removed() {
                        self.set(c);
                    }
                }
            }
        }
    }
</code></pre>

<p>The choice of implimenting tiles like this made it really easy to add new ones, and change
the way they react with each other to change the way the simulation plays out.</p>]]></content><author><name></name></author><category term="GameJam" /><summary type="html"><![CDATA[Protect your carrot patch from encroaching weeds. Made with my rust game library in 48 hours for global game jam 2023. Click next turn to advance time by a few step, and you can watch as the game world changes. When the carrots sparkle, it means they have been harvested and added to your carrot bank in the top right. You can click on the button in the top left to open the shop and buy tiles that interact with the world in some way. download on itch.io view source code on github Credits: Laura King - Art and Game Design Noam Zeise - Programming and Game Design Mick Cooke – MakeFire Music - Music and Sound Effects Implementation Details I added many new features to my Rust game library since I had last used it for a jam, now it hides all of the details of SDL. Controls are also much easier to add, and a lot of unrelated systems that were previously connected have been more seperated (ie render, input, camera, map, etc…). The Board is implimented as an array of Boxed objects that impliment the ‘Tile’ trait. This trait defines the behavior of a tile type, what it looks like, how it affects other tiles, and how other tiles affect it. Here is the trait pub trait Tile { fn tile(&amp;self) -&gt; Tiles { Tiles::None } fn pos(&amp;self) -&gt; (usize, usize); fn removed(&amp;mut self) -&gt; bool { false } fn update(&amp;mut self, _map: &amp;mut Tilemap) {} fn draw(&amp;self, _cam: &amp;mut Camera) {} fn interact(&amp;mut self, _tile:Tiles) {} } When the simulation steps forward, the update function is called on each tile. Each tile can add a Choice to the tilemap, which is a request for affecting a certain tile. Each of these choices are looped through and applied to their targets. The choice has two affects, it can either cause the target to be replaced, or will cause a change in the state of the target. fn step(&amp;mut self, ui: &amp;mut Ui) { for t in self.obj_map.iter_mut() { t.update(&amp;mut self.board); } for c in self.board.map_updates.drain(..) { if self.obj_map[c.i].tile() == Tiles::Grass { self.set(c); } else { self.obj_map[c.i].interact(c.dst); if self.obj_map[c.i].removed() { self.set(c); } } } } } The choice of implimenting tiles like this made it really easy to add new ones, and change the way they react with each other to change the way the simulation plays out.]]></summary></entry><entry><title type="html">Robyn Hood - on rails stealth card game</title><link href="http://localhost:4000/gamejam/2022/09/28/Robyn-Hood.html" rel="alternate" type="text/html" title="Robyn Hood - on rails stealth card game" /><published>2022-09-28T00:00:00+01:00</published><updated>2022-09-28T00:00:00+01:00</updated><id>http://localhost:4000/gamejam/2022/09/28/Robyn-Hood</id><content type="html" xml:base="http://localhost:4000/gamejam/2022/09/28/Robyn-Hood.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/Vgt7zBQWTyE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
<p><br />
An on-rails stealth game with spell cards, made over the course of 2 months for OGAM-16 with my C++ graphics, audio and map loading libraries. This was the work of a team of 3.</p>

<p>The game reimagines the legendary Robin Hood as a woman, and the player is her spirit guardian. It is the player’s task to cast spells to assit Robyn with her thievery. The player always has access to three basic spells: Go, Wait, and Retry. As the player goes through the level, the player can pick up stone spells for destroying obstacles and distracting enemies, a gust spell that can be used to displace the player and enemies, and a smoke spell for blinding enemies. The player must use these spells to help Robyn sneak past enemies.</p>

<p><a href="https://noamzeise.itch.io/robyn-hood">download on itch.io</a></p>

<p><a href="https://github.com/NoamZeise/Robyn-Hood">view source code on github</a></p>

<h4 id="credits">Credits:</h4>

<ul>
  <li>
    <p><a href="https://youtube.com/channel/UCs75GjfGdtTS-CekMJOGICA">Mick Cooke – MakeFire Music</a> - Music and Sound Effects</p>
  </li>
  <li>
    <p><a href="https://www.artstation.com/tha-com-nos">Thanos Gramosis</a> - Art</p>
  </li>
  <li>
    <p>Noam Zeise - Programming</p>
  </li>
</ul>]]></content><author><name></name></author><category term="GameJam" /><summary type="html"><![CDATA[An on-rails stealth game with spell cards, made over the course of 2 months for OGAM-16 with my C++ graphics, audio and map loading libraries. This was the work of a team of 3. The game reimagines the legendary Robin Hood as a woman, and the player is her spirit guardian. It is the player’s task to cast spells to assit Robyn with her thievery. The player always has access to three basic spells: Go, Wait, and Retry. As the player goes through the level, the player can pick up stone spells for destroying obstacles and distracting enemies, a gust spell that can be used to displace the player and enemies, and a smoke spell for blinding enemies. The player must use these spells to help Robyn sneak past enemies. download on itch.io view source code on github Credits: Mick Cooke – MakeFire Music - Music and Sound Effects Thanos Gramosis - Art Noam Zeise - Programming]]></summary></entry><entry><title type="html">ZL001 - Assembly Programming Game</title><link href="http://localhost:4000/demo/2022/07/31/ZL100.html" rel="alternate" type="text/html" title="ZL001 - Assembly Programming Game" /><published>2022-07-31T00:00:00+01:00</published><updated>2022-07-31T00:00:00+01:00</updated><id>http://localhost:4000/demo/2022/07/31/ZL100</id><content type="html" xml:base="http://localhost:4000/demo/2022/07/31/ZL100.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/lzEfdocz_m0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br />
<a href="https://github.com/NoamZeise/ZL001">Source Code + Build on Github</a>
<br />
The news that puzzle game studio <a href="https://www.zachtronics.com/">zachtronics</a> would stop making games inspired me to begin 
creating a little game in the style of some of their programming games (<a href="https://www.zachtronics.com/tis-100/">TS100</a>, <a href="https://www.zachtronics.com/shenzhen-io/">ShenzenIO</a>, <a href="https://www.zachtronics.com/exapunks/">Exapunks</a>).
I’m using this project to play about with a library(<a href="https://github.com/Rust-SDL2/rust-sdl2">SDL2</a>) and a language(Rust) I haven’t used for games before. 
I’ve been working on it slowly and I have some of the more basic mechanics 
in a playable form.</p>

<p><img src="/assets/img/posts/ZL001Old/zl001-ss.png" /></p>

<p>The game has a custom text editor and a circuit creation gui. It doesn’t have any levels yet, 
instead it works as a sandbox. 
The GUI handles writing code, placing/deleting microcontrollers,
connecting IO ports together, saving/loading and compiling/stepping the code. 
The shell shows the state of the registers after every execution step and any compile errors.</p>

<p>As you can see from the video the circuit designer lets you place microcontrollers and connect up 
their IO ports. They can then be programmed to do whatever is desired. 
The code can be stepped through and the shell shows which values are in each of the registers,
as well as if the microcontroller is waiting for an io port.</p>

<h2 id="the-language">The Language</h2>

<p><img src="/assets/img/posts/ZL001Old/zlo001-ss2.png" /></p>

<p>The language is not accurate assembly, it does not correspond one to one with a binary format, it is inspired by the languages from zachtronic games, as well as other fake assembly langauges like Sigma16.</p>

<p>What makes it unique from the usual zach-like languages is that code lables are just converted to numbers, so register, direct addresses, inputs can all be used as branch destinations. Another difference is that the program counter is treated as a normal register that the programmer can manipulate, which would make it possible to have simple functions.</p>

<p>The langauge is made up of a series of instructions, which are for:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>maths -&gt; ADD, SUB, MUL, DIV
branching -&gt; CMP, BRC, BEQ, BGT, BLT
no operation -&gt; NOP
halt -&gt; HLT
</code></pre></div></div>

<p>Each instruction can be followed by up to three operands depending on the instruction.</p>

<p>An operand is a value (which includes lables), or a register. Each microcontroller has 4 normal register and 4 IO registers.</p>

<p>The registers are:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PC -&gt; Program Counter
RT -&gt; Test register (holds CMP flags)
R1, R2 -&gt; General Registers
IO0, IO1, IO2, IO3 -&gt; IO registers, can be read to or written from (blocks until another microcontroller read/writes the value)
</code></pre></div></div>

<h2 id="experience-with-sdl2-and-rust">Experience with SDL2 and Rust</h2>

<p>I found SDL2 to be pretty unintuitive compared to frameworks like Monogame, I had to look at a lot of example code and check the source code to see what it was doing. I didn’t like the system of a canvas being passed around. The Rust borrow checker also meant that a lot of types that rely on the sdl2 lifetime needed to have explicit lifetimes.</p>

<p>Once I had made a few helper functions in place to handle texture/font loading and drawing it became a lot more managable. I moved the sdl2 resources to resource managers and just exposed cheap representations of the resource to the rest of the game. I found Rust to be enjoyable to use, but I definitely found myself missing some of the freedom that comes with C++.</p>

<p>The amount of string parsing functions that Rust has, the easy to use iterator system, and the pattern match syntax, made this specific program fun to code. I found being thorough with my error checking to be much easier with rust, as it really encourages you to handle errors, instead of having to remember to do it yourself.</p>

<h2 id="whats-next">What’s next</h2>

<p>The next stage of this project would be to add in input and output devices that would give the user some sort of puzzle to complete with the provided sandbox, as in a zach-like game. But for now I will be putting this on hold to work on other things. I will have to overhaul the rendering, to make it more friendly for resolution scaling.</p>]]></content><author><name></name></author><category term="Demo" /><summary type="html"><![CDATA[Source Code + Build on Github The news that puzzle game studio zachtronics would stop making games inspired me to begin creating a little game in the style of some of their programming games (TS100, ShenzenIO, Exapunks). I’m using this project to play about with a library(SDL2) and a language(Rust) I haven’t used for games before. I’ve been working on it slowly and I have some of the more basic mechanics in a playable form. The game has a custom text editor and a circuit creation gui. It doesn’t have any levels yet, instead it works as a sandbox. The GUI handles writing code, placing/deleting microcontrollers, connecting IO ports together, saving/loading and compiling/stepping the code. The shell shows the state of the registers after every execution step and any compile errors. As you can see from the video the circuit designer lets you place microcontrollers and connect up their IO ports. They can then be programmed to do whatever is desired. The code can be stepped through and the shell shows which values are in each of the registers, as well as if the microcontroller is waiting for an io port. The Language The language is not accurate assembly, it does not correspond one to one with a binary format, it is inspired by the languages from zachtronic games, as well as other fake assembly langauges like Sigma16. What makes it unique from the usual zach-like languages is that code lables are just converted to numbers, so register, direct addresses, inputs can all be used as branch destinations. Another difference is that the program counter is treated as a normal register that the programmer can manipulate, which would make it possible to have simple functions. The langauge is made up of a series of instructions, which are for: maths -&gt; ADD, SUB, MUL, DIV branching -&gt; CMP, BRC, BEQ, BGT, BLT no operation -&gt; NOP halt -&gt; HLT Each instruction can be followed by up to three operands depending on the instruction. An operand is a value (which includes lables), or a register. Each microcontroller has 4 normal register and 4 IO registers. The registers are: PC -&gt; Program Counter RT -&gt; Test register (holds CMP flags) R1, R2 -&gt; General Registers IO0, IO1, IO2, IO3 -&gt; IO registers, can be read to or written from (blocks until another microcontroller read/writes the value) Experience with SDL2 and Rust I found SDL2 to be pretty unintuitive compared to frameworks like Monogame, I had to look at a lot of example code and check the source code to see what it was doing. I didn’t like the system of a canvas being passed around. The Rust borrow checker also meant that a lot of types that rely on the sdl2 lifetime needed to have explicit lifetimes. Once I had made a few helper functions in place to handle texture/font loading and drawing it became a lot more managable. I moved the sdl2 resources to resource managers and just exposed cheap representations of the resource to the rest of the game. I found Rust to be enjoyable to use, but I definitely found myself missing some of the freedom that comes with C++. The amount of string parsing functions that Rust has, the easy to use iterator system, and the pattern match syntax, made this specific program fun to code. I found being thorough with my error checking to be much easier with rust, as it really encourages you to handle errors, instead of having to remember to do it yourself. What’s next The next stage of this project would be to add in input and output devices that would give the user some sort of puzzle to complete with the provided sandbox, as in a zach-like game. But for now I will be putting this on hold to work on other things. I will have to overhaul the rendering, to make it more friendly for resolution scaling.]]></summary></entry><entry><title type="html">3D Skeletal Animation With Vulkan</title><link href="http://localhost:4000/demo/2022/06/28/3D-Skeletal-Animation.html" rel="alternate" type="text/html" title="3D Skeletal Animation With Vulkan" /><published>2022-06-28T00:00:00+01:00</published><updated>2022-06-28T00:00:00+01:00</updated><id>http://localhost:4000/demo/2022/06/28/3D-Skeletal-Animation</id><content type="html" xml:base="http://localhost:4000/demo/2022/06/28/3D-Skeletal-Animation.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/kic2IAvDSM8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>I’ve added Skeletal animation to my Vulkan game framwork. I already use assimp to load in 3D models,
but the library also loads animations if the model has them.
I’ve revamped the model loading system to be able to load animated and non-animated 
models auutomically, and the renderer can take a model and an animation 
and render the current state of the animation to the screen.</p>

<p><a href="https://github.com/NoamZeise/Vulkan-Environment">Vulkan Framwork Source Code</a></p>

<p><a href="https://free3d.com/3d-model/wolf-rigged-and-game-ready-42808.html">Model I used: Wolf by 3D Haupt</a></p>

<h2 id="how-it-works">How it works</h2>

<p>The Animation is stored as a hierarchy of bones, where each bone has a number of keyframes for scale, position and rotation, and a parent bone.</p>

<p>Each bone corresponds to a 4×4 transform matrix that transforms the verticies from local to bone space. These transform matricies are calculated each frame and applied in the shader. In my implementation I send a uniform that holds and array of bone transform matricies that can be accessed by the animated verticies.</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">int</span> <span class="n">MAX_BONES</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span>
<span class="k">layout</span><span class="p">(</span><span class="n">set</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">binding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">uniform</span> <span class="n">boneView</span>
<span class="p">{</span>
   <span class="kt">mat4</span> <span class="n">mat</span><span class="p">[</span><span class="n">MAX_BONES</span><span class="p">];</span>
<span class="p">}</span> <span class="n">bones</span><span class="p">;</span>
</code></pre></div></div>
<p>As the animation plays, the current frame’s bone matricies are calculated using the keyframes of each bone. When an animation timing lands between two keyframes, the state is linearly interpreted using the two surrounding frames and the time the animation is at. Furthermore each matrix is multiplied by it’s parent’s matrix so that, say, a hand will move if an arm moves, without having to specifically move the hand too.</p>

<p>Each vertex on the model has a number of bone IDs and weights, which represent which bone transforms affect the matrix, and by how much. The weights add up to 1.0 per vertex.</p>

<p>So that the weights and IDs can be sent more easily to the shader as a vec4 and an ivec4, models usually limit the number of bones that affect a vertex to 4. So that the shader’s vertex inputs look like this:</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">in</span> <span class="kt">vec3</span> <span class="n">inPos</span><span class="p">;</span>
<span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="k">in</span> <span class="kt">vec3</span> <span class="n">inNormal</span><span class="p">;</span>
<span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="k">in</span> <span class="kt">vec2</span> <span class="n">inTexCoord</span><span class="p">;</span>
<span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span> <span class="k">in</span> <span class="kt">ivec4</span> <span class="n">inBoneIDs</span><span class="p">;</span> <span class="c1">//which bone matricies to use</span>
<span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span> <span class="k">in</span> <span class="kt">vec4</span> <span class="n">inWeights</span><span class="p">;</span> <span class="c1">//how much it affects</span>
</code></pre></div></div>
<p>I add up each bone matrix into one big ‘skin’ matrix and apply it to the vertex to get it into bone space. This is also applied to the normal to ensure lighting calculations account for the animation.</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">mat4</span> <span class="n">skin</span> <span class="o">=</span> <span class="kt">mat4</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">);</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="p">{</span>
   <span class="k">if</span><span class="p">(</span><span class="n">inBoneIDs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="o">||</span> <span class="n">inBoneIDs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">MAX_BONES</span><span class="p">)</span>
      <span class="k">break</span><span class="p">;</span>
   <span class="n">skin</span> <span class="o">+=</span> <span class="n">inWeights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">bones</span><span class="p">.</span><span class="n">mat</span><span class="p">[</span><span class="n">inBoneIDs</span><span class="p">[</span><span class="n">i</span><span class="p">]];</span>
<span class="p">}</span>

<span class="c1">// final_pos = projection * view * model * skin * position</span>
<span class="c1">// final_normal = normal_matrix * skin * normal</span>
</code></pre></div></div>
<p>If the animation is updated each frame by the game loop to get new bone matricies, 
then the model will be animated by the shader.</p>]]></content><author><name></name></author><category term="Demo" /><summary type="html"><![CDATA[I’ve added Skeletal animation to my Vulkan game framwork. I already use assimp to load in 3D models, but the library also loads animations if the model has them. I’ve revamped the model loading system to be able to load animated and non-animated models auutomically, and the renderer can take a model and an animation and render the current state of the animation to the screen. Vulkan Framwork Source Code Model I used: Wolf by 3D Haupt How it works The Animation is stored as a hierarchy of bones, where each bone has a number of keyframes for scale, position and rotation, and a parent bone. Each bone corresponds to a 4×4 transform matrix that transforms the verticies from local to bone space. These transform matricies are calculated each frame and applied in the shader. In my implementation I send a uniform that holds and array of bone transform matricies that can be accessed by the animated verticies. const int MAX_BONES = 50; layout(set = 2, binding = 0) uniform boneView { mat4 mat[MAX_BONES]; } bones; As the animation plays, the current frame’s bone matricies are calculated using the keyframes of each bone. When an animation timing lands between two keyframes, the state is linearly interpreted using the two surrounding frames and the time the animation is at. Furthermore each matrix is multiplied by it’s parent’s matrix so that, say, a hand will move if an arm moves, without having to specifically move the hand too. Each vertex on the model has a number of bone IDs and weights, which represent which bone transforms affect the matrix, and by how much. The weights add up to 1.0 per vertex. So that the weights and IDs can be sent more easily to the shader as a vec4 and an ivec4, models usually limit the number of bones that affect a vertex to 4. So that the shader’s vertex inputs look like this: layout(location = 0) in vec3 inPos; layout(location = 1) in vec3 inNormal; layout(location = 2) in vec2 inTexCoord; layout(location = 3) in ivec4 inBoneIDs; //which bone matricies to use layout(location = 4) in vec4 inWeights; //how much it affects I add up each bone matrix into one big ‘skin’ matrix and apply it to the vertex to get it into bone space. This is also applied to the normal to ensure lighting calculations account for the animation. mat4 skin = mat4(0.0f); for(int i = 0; i &lt; 4; i++) { if(inBoneIDs[i] == -1 || inBoneIDs[i] &gt;= MAX_BONES) break; skin += inWeights[i] * bones.mat[inBoneIDs[i]]; } // final_pos = projection * view * model * skin * position // final_normal = normal_matrix * skin * normal If the animation is updated each frame by the game loop to get new bone matricies, then the model will be animated by the shader.]]></summary></entry><entry><title type="html">Trials Of The Pharaoh - Light Ray Puzzle Game</title><link href="http://localhost:4000/gamejam/2022/05/30/TrialsOfThePharaoh.html" rel="alternate" type="text/html" title="Trials Of The Pharaoh - Light Ray Puzzle Game" /><published>2022-05-30T00:00:00+01:00</published><updated>2022-05-30T00:00:00+01:00</updated><id>http://localhost:4000/gamejam/2022/05/30/TrialsOfThePharaoh</id><content type="html" xml:base="http://localhost:4000/gamejam/2022/05/30/TrialsOfThePharaoh.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/fsNIisWhVz8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>An Egyptian light ray puzzle game, made in 10 days for GDTV Jam 2022 with my Vulkan and OpenGL graphics libraries. I worked together with the same people that made The Last Dodo with me.</p>

<p>This is the first project where I have both a Vulkan and an OpenGL executable, this ensures that those with older gpus or outdated drivers will still be able to play (before I had a few people complaing about the game not working for them).</p>

<p>Out of 950 submissions, we managed to get 1st place in both the “fun” and “music” categories, 4th in “Mechanics” and “Sound”, and 5th in “Aesthetics”. Which I am very happy with.</p>

<p><a href="https://noamzeise.itch.io/pharaoh-trials">download on itch.io</a></p>

<p><a href="https://github.com/NoamZeise/TrailsOfThePharaoh">view source code on github</a></p>

<h4 id="credits">Credits:</h4>

<ul>
  <li>
    <p><a href="https://youtube.com/channel/UCs75GjfGdtTS-CekMJOGICA">Mick Cooke – MakeFire Music</a> - Music</p>
  </li>
  <li>
    <p><a href="https://www.artstation.com/tha-com-nos">Thanos Gramosis</a> - Art</p>
  </li>
  <li>
    <p>Paul James – Wafer Audio - Sound</p>
  </li>
  <li>
    <p>Paulina Ramirez –  Lady Yami #3939 - Voice Over/Writing</p>
  </li>
  <li>
    <p>Noam Zeise - Programming</p>
  </li>
</ul>

<h2 id="technical-details">Technical Details:</h2>

<p><strong>2D Light Ray Shader</strong></p>

<p>Shaders played a big role in this game, the light ray effect is generated 
by the fragment shader.</p>

<p>The rays begin from an emitter, and shoot out into the game map. The map is stored as a series of lines, so a square will have 4 lines for example.
I step forward by a large amount of units and check each surface to see if the ray intersected any lines, 
if it did, I roll back the ray to half the previous step and check again. If there was still a collision I go half again back, if not,
I go half again forward. This is repeat until the ray is at the desired detail level. 
If the surface is a mirror, the ray is reflected based on the laws of reflection and I repeat the above steps, 
until I have a series of start and end points for rays. There is a cutoff of reflections to prevent an infinite loop, and to ensure the shader buffer isn’t exceeded.</p>

<p>The array of start and end points are converted from game coords to screen coords, then sent to a storage buffer 
on the gpu at the start of the frame. these points are accessed from the fragment shader, 
which modify the brightness of a pixel based on how close each fragment is to a line. 
The intensity is also modified by time with a sine function to give the rays a “pulsing” effect in the direction of travel.</p>

<p><img src="/assets/img/posts/trialspharaoh/light-anim.webp" /></p>

<p>The light ray shader takes in an array of pairs of points and a distance 
that I store in a shader buffer. 
I calculate the distance on the cpu so that it does not need to be recalculated for each fragment.</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">int</span> <span class="n">RAY_COUNT</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<span class="k">layout</span><span class="p">(</span><span class="n">set</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">binding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="n">readonly</span> <span class="n">buffer</span> <span class="n">PerFrameLightPoints</span><span class="p">{</span>
  <span class="kt">vec2</span> <span class="n">p1</span><span class="p">;</span>
  <span class="kt">vec2</span> <span class="n">p2</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">distance</span><span class="p">;</span>
<span class="p">}</span> <span class="n">rays</span><span class="p">[</span><span class="n">RAY_COUNT</span><span class="p">];</span>
</code></pre></div></div>
<p>I also send in a time value that I use to produce the wave effect the light has.</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">layout</span><span class="p">(</span><span class="n">location</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="k">in</span> <span class="kt">float</span> <span class="n">time</span><span class="p">;</span>
</code></pre></div></div>

<p>I calculate the value of the fragment by summing the effect of each ray into 
an attenuation value that I use to modify the colour towards yellow. The closer the fragment
is to the line between the two points, the brighter it is.</p>
<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">vec4</span> <span class="n">col</span> <span class="o">=</span> <span class="n">texture</span><span class="p">(</span><span class="kt">sampler2D</span><span class="p">(</span><span class="n">textures</span><span class="p">[</span><span class="n">texID</span><span class="p">],</span> <span class="n">texSamp</span><span class="p">),</span> <span class="n">coord</span><span class="p">)</span> <span class="o">*</span> <span class="n">colour</span><span class="p">;</span>

<span class="kt">float</span> <span class="n">attenuation</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
<span class="c1">// add to the attenuation the effects of each ray on the fragment</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">RAY_COUNT</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="p">{</span>
	<span class="c1">//  I set the last ray distance to zero to break the loop early</span>
	<span class="k">if</span><span class="p">(</span><span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">distance</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
		<span class="k">break</span><span class="p">;</span>
	
	<span class="kt">float</span> <span class="n">dist</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
	<span class="c1">// Get the square distance from the start point to the end point</span>
	<span class="kt">vec2</span> <span class="n">lineVec</span> <span class="o">=</span> <span class="p">(</span><span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p2</span> <span class="o">-</span> <span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">);</span>
	<span class="kt">float</span> <span class="n">l2</span> <span class="o">=</span> <span class="p">(</span><span class="n">lineVec</span><span class="p">.</span><span class="n">x</span><span class="o">*</span> <span class="n">lineVec</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">lineVec</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">lineVec</span><span class="p">.</span><span class="n">y</span><span class="p">);</span>
	<span class="c1">// If the ray has no length, we calculate the distance </span>
	<span class="c1">// from the start point to the fragment</span>
	<span class="k">if</span><span class="p">(</span><span class="n">l2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">)</span>
		<span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">,</span> <span class="nb">gl_FragCoord</span><span class="p">.</span><span class="n">xy</span><span class="p">);</span>
	<span class="c1">// Otherwise we calc the distance from the fragment </span>
	<span class="c1">// and the line between the two points by projecting the</span>
	<span class="c1">// fragment onto the line and getting the distance between</span>
	<span class="c1">// that point and the fragment pos</span>
	<span class="k">else</span>
	<span class="p">{</span>
		<span class="kt">float</span> <span class="n">t</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dot</span><span class="p">(</span><span class="nb">gl_FragCoord</span><span class="p">.</span><span class="n">xy</span> <span class="o">-</span> <span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">,</span> 
			<span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p2</span> <span class="o">-</span> <span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">)</span> <span class="o">/</span> <span class="n">l2</span><span class="p">));</span>
		<span class="kt">vec2</span> <span class="n">projection</span> <span class="o">=</span> <span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span> <span class="o">+</span> <span class="p">(</span><span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p2</span> <span class="o">-</span> <span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">)</span><span class="o">*</span><span class="n">t</span><span class="p">;</span>
		<span class="kt">float</span> <span class="n">fromStart</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="n">rays</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">p1</span><span class="p">,</span> <span class="nb">gl_FragCoord</span><span class="p">.</span><span class="n">xy</span><span class="p">);</span>
		<span class="c1">// add a sinusoidal wave effect to the light over time</span>
		<span class="kt">float</span> <span class="n">correction</span> <span class="o">=</span> <span class="n">abs</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">fromStart</span> <span class="o">*</span> <span class="mi">0</span><span class="p">.</span><span class="mo">01</span><span class="n">f</span> <span class="o">-</span> <span class="n">time</span><span class="p">))</span><span class="o">*</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span> <span class="o">+</span> <span class="mi">0</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="p">;</span>
		<span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="nb">gl_FragCoord</span><span class="p">.</span><span class="n">xy</span><span class="p">,</span> <span class="n">projection</span><span class="p">)</span> <span class="o">/</span> <span class="n">correction</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">attenuation</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span> <span class="o">+</span> <span class="mi">0</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span> <span class="o">*</span> <span class="n">dist</span> <span class="o">+</span> <span class="mi">0</span><span class="p">.</span><span class="mo">05</span><span class="n">f</span> <span class="o">*</span> <span class="n">dist</span> <span class="o">*</span> <span class="n">dist</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// add yellow to the colour based on the effect of the light rays</span>
<span class="n">col</span> <span class="o">+=</span> <span class="kt">vec4</span><span class="p">(</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">,</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">7882352941</span><span class="n">f</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">)</span> <span class="o">*</span> <span class="n">attenuation</span><span class="p">;</span>
</code></pre></div></div>
<p><br /><br />
<strong>Vulkan and OpenGL differences</strong></p>

<p>I used preprocessor directives to include either version of the graphics libraries (which have identical outward-facing APIs) 
(Now I am using volk which means I don’t statically link to vulkan, so I only have 1 binary).
This builds two versions of the game, which isn’t ideal in terms of file size, as it adds 1.8MB to the download. 
The binaries can use the same folders for textures, audio, and other resources (but they both need their own shaders as OpenGL glsl is a little different from Vulkan glsl).</p>

<p>Both versions look almost identical on my hardware:</p>

<p>Vulkan:</p>

<p><img src="/assets/img/posts/trialspharaoh/comparisonv1-1.webp" style="width:48%" />
<img src="/assets/img/posts/trialspharaoh/comparisonv2.webp" style="width:48%" /></p>

<p>OpenGL:</p>

<p><img src="/assets/img/posts/trialspharaoh/comparisono1-1.webp" style="width:48%" />
<img src="/assets/img/posts/trialspharaoh/comparisono2.webp" style="width:48%" /></p>

<p>The major difference can be seem in the text, it looks sharper and blockier to me in OpenGL, 
I expect this is down to the difference in how each rendering pipeline is set up. 
My Vulkan library draws it’s rendered image to a quad which is then scaled to fit the screen backbuffer. 
The OpenGL implimentation just directly draws on the screen buffer, modifying the draws to account for the backbuffer size.</p>]]></content><author><name></name></author><category term="GameJam" /><summary type="html"><![CDATA[An Egyptian light ray puzzle game, made in 10 days for GDTV Jam 2022 with my Vulkan and OpenGL graphics libraries. I worked together with the same people that made The Last Dodo with me. This is the first project where I have both a Vulkan and an OpenGL executable, this ensures that those with older gpus or outdated drivers will still be able to play (before I had a few people complaing about the game not working for them). Out of 950 submissions, we managed to get 1st place in both the “fun” and “music” categories, 4th in “Mechanics” and “Sound”, and 5th in “Aesthetics”. Which I am very happy with. download on itch.io view source code on github Credits: Mick Cooke – MakeFire Music - Music Thanos Gramosis - Art Paul James – Wafer Audio - Sound Paulina Ramirez – Lady Yami #3939 - Voice Over/Writing Noam Zeise - Programming Technical Details: 2D Light Ray Shader Shaders played a big role in this game, the light ray effect is generated by the fragment shader. The rays begin from an emitter, and shoot out into the game map. The map is stored as a series of lines, so a square will have 4 lines for example. I step forward by a large amount of units and check each surface to see if the ray intersected any lines, if it did, I roll back the ray to half the previous step and check again. If there was still a collision I go half again back, if not, I go half again forward. This is repeat until the ray is at the desired detail level. If the surface is a mirror, the ray is reflected based on the laws of reflection and I repeat the above steps, until I have a series of start and end points for rays. There is a cutoff of reflections to prevent an infinite loop, and to ensure the shader buffer isn’t exceeded. The array of start and end points are converted from game coords to screen coords, then sent to a storage buffer on the gpu at the start of the frame. these points are accessed from the fragment shader, which modify the brightness of a pixel based on how close each fragment is to a line. The intensity is also modified by time with a sine function to give the rays a “pulsing” effect in the direction of travel. The light ray shader takes in an array of pairs of points and a distance that I store in a shader buffer. I calculate the distance on the cpu so that it does not need to be recalculated for each fragment. const int RAY_COUNT = 100; layout(set = 4, binding = 0) readonly buffer PerFrameLightPoints{ vec2 p1; vec2 p2; float distance; } rays[RAY_COUNT]; I also send in a time value that I use to produce the wave effect the light has. layout(location = 2) in float time; I calculate the value of the fragment by summing the effect of each ray into an attenuation value that I use to modify the colour towards yellow. The closer the fragment is to the line between the two points, the brighter it is. vec4 col = texture(sampler2D(textures[texID], texSamp), coord) * colour; float attenuation = 0.0f; // add to the attenuation the effects of each ray on the fragment for(int i = 0; i &lt; RAY_COUNT; i++) { // I set the last ray distance to zero to break the loop early if(rays[i].distance == 0) break; float dist = 0.0f; // Get the square distance from the start point to the end point vec2 lineVec = (rays[i].p2 - rays[i].p1); float l2 = (lineVec.x* lineVec.x) + (lineVec.y*lineVec.y); // If the ray has no length, we calculate the distance // from the start point to the fragment if(l2 == 0.0f) dist = distance(rays[i].p1, gl_FragCoord.xy); // Otherwise we calc the distance from the fragment // and the line between the two points by projecting the // fragment onto the line and getting the distance between // that point and the fragment pos else { float t = max(0, min(1, dot(gl_FragCoord.xy - rays[i].p1, rays[i].p2 - rays[i].p1) / l2)); vec2 projection = rays[i].p1 + (rays[i].p2 - rays[i].p1)*t; float fromStart = distance(rays[i].p1, gl_FragCoord.xy); // add a sinusoidal wave effect to the light over time float correction = abs(sin(fromStart * 0.01f - time))*0.5f + 0.3f; dist = distance(gl_FragCoord.xy, projection) / correction; } attenuation += 1.0f / (1.0f + 0.3f * dist + 0.05f * dist * dist); } // add yellow to the colour based on the effect of the light rays col += vec4(1.0f, 1.0f, 0.7882352941f, 0.0f) * attenuation; Vulkan and OpenGL differences I used preprocessor directives to include either version of the graphics libraries (which have identical outward-facing APIs) (Now I am using volk which means I don’t statically link to vulkan, so I only have 1 binary). This builds two versions of the game, which isn’t ideal in terms of file size, as it adds 1.8MB to the download. The binaries can use the same folders for textures, audio, and other resources (but they both need their own shaders as OpenGL glsl is a little different from Vulkan glsl). Both versions look almost identical on my hardware: Vulkan: OpenGL: The major difference can be seem in the text, it looks sharper and blockier to me in OpenGL, I expect this is down to the difference in how each rendering pipeline is set up. My Vulkan library draws it’s rendered image to a quad which is then scaled to fit the screen backbuffer. The OpenGL implimentation just directly draws on the screen buffer, modifying the draws to account for the backbuffer size.]]></summary></entry><entry><title type="html">Raspberry Pi Pico Temperature Sensor</title><link href="http://localhost:4000/microcontroller/2022/04/13/temp-humidity.html" rel="alternate" type="text/html" title="Raspberry Pi Pico Temperature Sensor" /><published>2022-04-13T00:00:00+01:00</published><updated>2022-04-13T00:00:00+01:00</updated><id>http://localhost:4000/microcontroller/2022/04/13/temp-humidity</id><content type="html" xml:base="http://localhost:4000/microcontroller/2022/04/13/temp-humidity.html"><![CDATA[<p>Using the raspberry pi pico microcontroller board with a DHT11 sensor, it tracks the temperature and relative humidity throughout the day. The Pico code is written in C++ and the cli is written in Rust.</p>

<p>The pico stores data into a buffer after a time interval, the buffer can be emptied to a computer using the command line tool, which sends a request to the pico over uart, then saves the data recieved as comma separated values.</p>

<p><a href="https://github.com/NoamZeise/pico-th-collector">source code</a></p>

<p>here’s data from the project recorded between 1:00am and 4:30pm:</p>

<p><img src="/assets/img/posts/pico-humidity/readings-temp.png" style="width:49%" />
<img src="/assets/img/posts/pico-humidity/readings-humidity.png" style="width:49%" /></p>

<p>The resolution of the humidity sensor is less than the temperature sensor, which is why the temperature graph is more detailed.</p>

<p><br />
<br /></p>
<h2 id="how-it-works">How it works</h2>

<hr />

<p><br /></p>
<h4 id="pico-code">Pico Code</h4>

<p>The pico runs on a loop where it sleeps for the delay period, then requests a sensor reading from the DHT11, which stores temperature, humidity and a timestamp in an array of 7 byte records.</p>

<p>The pico has a number of general purpose input output (GPIO) pins that detect whether the voltage across it is high or low. So by connecting the DHT11 to one of the GPIO pins the pico and send and recieve data from the sensor. The specifics of how the data is sent can be read about <a href="https://components101.com/sites/default/files/component_datasheet/DHT11-Temperature-Sensor.pdf">here</a>.</p>

<p>The DHT11 outputs 2 bytes for both temperature and humidity (but humidity only has 1 bytes of precision, it outputs two so it’s compatible with the DHT22), as well as a check byte. This data is stored as bytes, the conversion to floats happens with the command line tool. I also have the pico store the time as 3 bytes, so it can store up to 190 days of timestamps. An interrupt occurs when the pico recieves data to the uart1 port, which is stored as a char array. A command is finished with a CRLF, which tells the pico to check the given command and execute it, as well as clear the command char array.</p>

<p>The pico returns a 1 byte response code to the given command: 1 meaing a confirmation, 2 meaing an empty buffer, 3 meaning an unknown command. In the case of a get command, the pico send 8 bytes for each recorded sensor reading. 7 bytes are for the data, and 1 byte is for syncing. This make sure missed bytes only affect two records, instead of offseting every byte afterwards.</p>

<p>The pico then resets it’s time, clears it’s buffer and continues getting sensor readings. The buffer size is 30,000 (this is 210kB, pico has 256kB ram total), so at the default reading of every 30 seconds, it should be able to run for 10 days without needing to be emptied.</p>

<p>The reading interval can be checked and changed with a delay command, which uses the same codes as the first command, then recieves a 1 byte number representing the delay in seconds, and returns the byte for checking.</p>

<p><img src="/assets/img/posts/pico-humidity/top-down-view.jpg" style="width:100%;" /></p>

<p><br /></p>
<h4 id="command-line-code">Command Line Code</h4>

<p>This is my first time working with Rust for something relatively low level like uart, and I found it a pleasant experience. The language made handling buffers very flexible, and the error handling was easy to implement.</p>

<p>The command line code uses the specifics of how the pico software sends it’s data/recieves commands. When asked to by the user, it sends a get command to the pico and reads 8 bytes per record, checking that the sync byte is correct. The user can get the current reading delay, or change it to something else (limted to the range of 1-255 seconds)</p>

<p>I wrote the tool to being very careful to check the user command is correct before getting the data, but once the program gets it from the device, it will rarely run into a stopping condition, this is to ensure that the data is usually preserved when an error occurs, even if it turns out to be a bit mangled.</p>

<p>The tool uses the <a href="https://crates.io/crates/serialport">serial port crate</a> which exposes a cross-platform serial port api for connecting to and using ports.</p>

<p><img src="/assets/img/posts/pico-humidity/file-output.png" style="width:100%;" /></p>

<p><br /></p>
<hr />

<p><br /></p>

<h2 id="setup">Setup</h2>

<p>If you want to use the software to run a cheap temperature recorder, these are the steps to follow. The components ended up costing me around £12.</p>

<p><img src="/assets/img/posts/pico-humidity/debug-view-setup.webp" /></p>

<p>You’ll need:</p>

<ul>
  <li>
    <p>A <a href="https://www.raspberrypi.com/products/raspberry-pi-pico/">Raspberry Pi Pico</a></p>
  </li>
  <li>
    <p>A <a href="https://components101.com/sensors/dht11-temperature-sensor">DHT11</a> or <a href="https://components101.com/sensors/dht22-pinout-specs-datasheet">DHT22</a>(untested) sensor</p>
  </li>
  <li>
    <p>Some sort of uart device with a baud rate set to 9600, such as the <a href="https://components101.com/wireless/hc-05-bluetooth-module">HC-05 bluetooth module</a></p>
  </li>
  <li>
    <p>A 5V power supply (can use batteries), or you can power over usb.</p>
  </li>
  <li>
    <p>Some wires for connecting the pins to the components, I used a breadboard and dupont wires.</p>
  </li>
  <li>
    <p>A micro usb to flash the software onto the pico.</p>
  </li>
  <li>
    <p>A windows or linux computer for running the command line tool to grab the data from the pico</p>
  </li>
</ul>

<p>Download the binaries from the <a href="https://github.com/NoamZeise/pico-th-collector/releases">release section of the github page</a>. You’ll need pico-th-collector.uf2  and either the <a href="https://github.com/NoamZeise/pico-th-collector/releases/download/0.1.0/pico_th_collector.exe">windows cli</a> or the <a href="https://github.com/NoamZeise/pico-th-collector/releases/download/0.1.0/pico_th_collector">linux cli</a>. First install the software by holding the BOOTSEL button and plugging the pico into a computer. The pico should open as an external flash drive, now drag the .uf2 file onto the pico. The pico is now flashed with the software.</p>

<p>Next wire up the pico as shown below:</p>

<p><img src="/assets/img/posts/pico-humidity/setup-diagram.webp" /></p>

<p>This is the information show in the image, with the pins named:</p>

<p><strong>Pico -&gt; DHT11</strong></p>

<ul>
  <li>
    <p>pin 21 GPI16 -&gt; Data</p>
  </li>
  <li>
    <p>VSYS -&gt; VCC</p>
  </li>
  <li>
    <p>GND -&gt; GND</p>
  </li>
</ul>

<p><strong>Pico -&gt; HC-05</strong></p>

<ul>
  <li>
    <p>pin 6 UART1 TX -&gt;  RXD</p>
  </li>
  <li>
    <p>pin 7 UART1 RX -&gt; TXD</p>
  </li>
  <li>
    <p>VSYS -&gt; VCC</p>
  </li>
  <li>
    <p>GND  -&gt; GND</p>
  </li>
</ul>

<p><strong>Power Supply</strong></p>

<ul>
  <li>
    <p>VSYS -&gt; positive terminal</p>
  </li>
  <li>
    <p>GND  -&gt; negative terminal</p>
  </li>
</ul>

<p>Note that the power supply doesn’t have to be connected to the VSYS and GND pins, plugging a usb into the micro-usb plug will also work.</p>

<p>Powering through USB:</p>

<p><img src="/assets/img/posts/pico-humidity/usb-powering.jpg" /></p>

<p>Powering through battery:</p>

<p><img src="/assets/img/posts/pico-humidity/battery-powering.jpg" /></p>

<p>Now the pico can be left to collect data, the LED on the pico should flash every time it collects a reading.
<br />
<br /></p>
<h2 id="using-the-command-line-tool">Using the Command Line Tool</h2>

<p>The pico can send you it’s collected readings over uart. You’ll need either a Window or Linux computer (and bluetooth if using uart bluetooth). If you have a mac, or the binaries don’t work on your architecture, you will need to build the command line tool yourself using Rust (See <em>Building the Command Line Tool</em> at the end of this article).</p>

<h4 id="get-command">get command</h4>

<p>The <code class="language-plaintext highlighter-rouge">get</code> command is used to get the data from the pico and save it to a file. It is used as</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    get [port] [file] [optional args]
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">[port]</code> is the name of the port that the pico’s uart1 is connected to. If you are using bluetooth uart, you will first need to pair your device with the bluetooth module before you can use the port.</p>

<p>If you are on windows, the <em>device manager</em> will show your available ports under <em>Ports</em> (the format is <code class="language-plaintext highlighter-rouge">COM[X]</code>), you can either try them all with the command line tool, or connect and disconnect the pico to see which port appears and disappears.</p>

<p>On linux the <code class="language-plaintext highlighter-rouge">dmesg | grep tty</code> command will output a history of usb devices connecting, the port will be in the /<code class="language-plaintext highlighter-rouge">dev/tty[device]</code> format. If you are using bluetooth you can pair with the device using <em>bluez</em>, then link it’s MAC address to an rfcomm port, so the port format would be <code class="language-plaintext highlighter-rouge">/dev/rfcomm[x]</code>.</p>

<p><img src="/assets/img/posts/pico-humidity/request-data-cli.webp" /></p>

<p>If the specified file already exists and is full of previous pico data, the user can specify the <code class="language-plaintext highlighter-rouge">-useprev</code> tag with the get command to use the last record in the file as an offset for the current data. This is used if you fetch data from the pico a second time after allowing it to continue to collect data.</p>

<p><img src="/assets/img/posts/pico-humidity/askforinfo-append.webp" /></p>

<p>The <code class="language-plaintext highlighter-rouge">-useoffset [offset in seconds]</code> tag will add the specified offset to the data (this can be used in conjunction with other args). This is useful if you want to append to preexisting data but the pico was off for a known time.</p>

<h4 id="delay-command">delay command</h4>

<p>The <code class="language-plaintext highlighter-rouge">delay</code> command is used to get and set the reading delay of the pico. It is used as:
```
    delay [port] [optional args]
``
Running the command without optinal args gets the current delay. The argument <code class="language-plaintext highlighter-rouge">--set [delay]</code> sets the pico’s delay to the given value in seconds.</p>

<p><img src="/assets/img/posts/pico-humidity/delay-cmd.webp" /></p>

<p><br /><br /><br /></p>
<hr />

<p><br /><br /></p>
<h2 id="pico-development-setup">Pico Development Setup</h2>

<p>If you want to modify the software, if you would like to change the GPIO pins or the uart port or anything else, or build the binaries for yourself, these next sections will help.</p>

<h3 id="pico-debugging-setup">Pico Debugging Setup</h3>

<p>The pico is designed to be used with a raspberry pi computer, which acts as a debugger for the board. As an alternative for those without a pi pc, raspberry pi offer software called picoprobe which, when flashed onto a pico, allows that pico to act as the debugger.</p>

<p><img src="/assets/img/posts/pico-humidity/debug-setup.webp" /></p>

<p>The three debug pins at the bottom need to be hooked up to the debugger pico and ground. It can also share power with the slave pico. The debugger lets you flash new software on the pico, set breakpoints, and see a log of any errors.</p>

<p><img src="/assets/img/posts/pico-humidity/debug-pins.jpg" /></p>

<p>For debugging, the debugger pico’s pins 4-GP2 (pin-label) and 5-GP3 are connected to the target’s SWCLK and SWDIO pins respectively. Wiring 39-VSYS and 38-GND to each other let the picos share power. You can also connect the debugger’s 6-UART1_TX and 7-UART2_RX to the target’s 2-UART0_RX and 1-UART0_TX respectively to pass the target pico’s uart0 through the debugger. Illustrated below (without the components connected):</p>

<p><img src="/assets/img/posts/pico-humidity/debug-diagram.png" /></p>

<p>For debugging software setup see <a href="https://datasheets.raspberrypi.com/pico/getting-started-with-pico.pdf">Getting Started with Raspberry Pi Pico</a> under Appendix A: Using Picoprobe. The dependancies section on the github repo also indicate which tools are needed for building the pico software.</p>

<h3 id="building-the-command-line-tool">Building the Command Line Tool</h3>

<p>The command line tool uses Rust, which you will need to <a href="https://www.rust-lang.org/tools/install">install</a>. This comes with the package manager cargo, which will make building the binaries simpler by managing it’s dependancies for you.</p>

<p>Once you have Rust, download the source code for the command line tool and navigate to it. Run <code class="language-plaintext highlighter-rouge">cargo build --release</code> to build the binaries in release mode. The binary will now be in <code class="language-plaintext highlighter-rouge">target\relase\</code> in the code directory.</p>]]></content><author><name></name></author><category term="microcontroller" /><summary type="html"><![CDATA[Using the raspberry pi pico microcontroller board with a DHT11 sensor, it tracks the temperature and relative humidity throughout the day. The Pico code is written in C++ and the cli is written in Rust.]]></summary></entry><entry><title type="html">Global Touch - DYHTG 2022 Winner</title><link href="http://localhost:4000/hackathon/2022/02/13/GlobalTouch.html" rel="alternate" type="text/html" title="Global Touch - DYHTG 2022 Winner" /><published>2022-02-13T00:00:00+00:00</published><updated>2022-02-13T00:00:00+00:00</updated><id>http://localhost:4000/hackathon/2022/02/13/GlobalTouch</id><content type="html" xml:base="http://localhost:4000/hackathon/2022/02/13/GlobalTouch.html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/QOnx-5Gtw9k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br /><br />
A python app with a database, made in 48 hours for Do you Have The Guts 2022
<br /><br />
The app used google cloud for hosting an SQL server, and tkinter for the GUI as well as some web apis to fetch the weather and news. I was mainly responsible for the GUI and it was my first time using tkinter.</p>

<p>The app allows employees working as part of an international team to see what the weather and news is like in their co-worker’s countries. Employees can also share what is interesting them, as well as any homepages they use frequently for getting their local news.</p>

<p>I was part of a team of four first year students, it was the first hackathon any of us had done. We competed in the JP Morgan challenge and won.</p>

<p><a href="https://gutechsoc.com/hackathon">hackathon site</a></p>

<p><a href="https://github.com/DanielHally/guts">Source Code</a></p>

<p>(the program will no longer work as the google cloud server was shutdown)</p>

<p><img src="/assets/img/posts/globaltouch.png" /></p>]]></content><author><name></name></author><category term="Hackathon" /><summary type="html"><![CDATA[A python app with a database, made in 48 hours for Do you Have The Guts 2022 The app used google cloud for hosting an SQL server, and tkinter for the GUI as well as some web apis to fetch the weather and news. I was mainly responsible for the GUI and it was my first time using tkinter. The app allows employees working as part of an international team to see what the weather and news is like in their co-worker’s countries. Employees can also share what is interesting them, as well as any homepages they use frequently for getting their local news. I was part of a team of four first year students, it was the first hackathon any of us had done. We competed in the JP Morgan challenge and won. hackathon site Source Code (the program will no longer work as the google cloud server was shutdown)]]></summary></entry><entry><title type="html">Generating A Mandelbrot BMP with C</title><link href="http://localhost:4000/demo/2021/10/20/mandelbrot.html" rel="alternate" type="text/html" title="Generating A Mandelbrot BMP with C" /><published>2021-10-20T00:00:00+01:00</published><updated>2021-10-20T00:00:00+01:00</updated><id>http://localhost:4000/demo/2021/10/20/mandelbrot</id><content type="html" xml:base="http://localhost:4000/demo/2021/10/20/mandelbrot.html"><![CDATA[<p><img src="/assets/img/posts/mandelbrotwithgrad.webp" /></p>

<p><a href="https://github.com/NoamZeise/bmp-read-write">Source Code on github</a></p>

<p>I generated an image representing the mandelbrot set by checking each pixel to see if it is a part of it and, if not, I make the pixel darker the faster it blows up to infinity.</p>

<p><a href="https://drive.google.com/file/d/1-0XPnFw6Bq2QASeEzgJ0FFdeRILcn6PC/view?usp=sharing">Here is the actual image file(10000×6600)</a></p>

<p>My program saved it as a bmp, then I converted it to another format to reduce the file size.</p>

<p>Here’s the function that generates the pattern:</p>

<pre><code class="language-C">double inMandelbrot(double x, double y)
{
  double _Complex c = x + (I*y);
  double _Complex z = 0;
  const int iterations = 200;
  const double ratio = 8.0/3.0;
  for(uint i = 0; i &lt; iterations; i++)
  {
    z = (z*z) + c;
    if(cabs(z) &gt; 2)
      return ((double)i / iterations) * ratio;
  }
  if(cabs(z) &gt; 2)
    return 0.0;
  else
    return 1.0;
}
</code></pre>]]></content><author><name></name></author><category term="Demo" /><summary type="html"><![CDATA[Source Code on github I generated an image representing the mandelbrot set by checking each pixel to see if it is a part of it and, if not, I make the pixel darker the faster it blows up to infinity. Here is the actual image file(10000×6600) My program saved it as a bmp, then I converted it to another format to reduce the file size. Here’s the function that generates the pattern: double inMandelbrot(double x, double y) { double _Complex c = x + (I*y); double _Complex z = 0; const int iterations = 200; const double ratio = 8.0/3.0; for(uint i = 0; i &lt; iterations; i++) { z = (z*z) + c; if(cabs(z) &gt; 2) return ((double)i / iterations) * ratio; } if(cabs(z) &gt; 2) return 0.0; else return 1.0; }]]></summary></entry><entry><title type="html">A* and Djikstra Shortest Path in C#</title><link href="http://localhost:4000/demo/2020/09/18/AStarDjikstra.html" rel="alternate" type="text/html" title="A* and Djikstra Shortest Path in C#" /><published>2020-09-18T00:00:00+01:00</published><updated>2020-09-18T00:00:00+01:00</updated><id>http://localhost:4000/demo/2020/09/18/AStarDjikstra</id><content type="html" xml:base="http://localhost:4000/demo/2020/09/18/AStarDjikstra.html"><![CDATA[<p><a href="https://github.com/NoamZeise/A-Djikstra-PathfindingAlgorithms/tree/master/PathfindingAlgorithms">Source Code</a></p>

<p>Djikstra is a common algorithm used to find the shortest paths from one node to all others, 
A* (A star) is a modification of djikstra that considers going from one node to one other.
A* considers how close a node is from the goal and prefers nodes that 
bring you closer to the end goal. 
This implimentation uses Djikstra to get the shortest path between two nodes, 
so that it can be compared to A*.</p>

<p>A square board is randomly generated and a few blocks are places to add complexity to the paths. 
Two random places on the grid are marked as start and end points for the algorithms to navigate.</p>

<p>The program shows The result of using both Dijsktra and A* pathfinding algorithms to 
find the shortest path between those points (if there are more than one, one is found at random).</p>

<p><img src="/assets/img/posts/pathingCS/pathfinding-ss1.png" /></p>

<p>The top shows Dijkstra, the bottom shows A*. The number of ticks and nodes each algorithm visited is also displayed.</p>

<p>The blue X represends the Start, the yellow X’s represents the path taken to get to the goal.</p>

<p>The red x’s are the nodes that were unexplored by the algorithm, the white ones being all the nodes visited but not part of the path.</p>

<p><img src="/assets/img/posts/pathingCS/pathfinding-s2.png" /></p>

<p><img src="/assets/img/posts/pathingCS/pathfinding-s3.png" /></p>]]></content><author><name></name></author><category term="Demo" /><summary type="html"><![CDATA[Source Code Djikstra is a common algorithm used to find the shortest paths from one node to all others, A* (A star) is a modification of djikstra that considers going from one node to one other. A* considers how close a node is from the goal and prefers nodes that bring you closer to the end goal. This implimentation uses Djikstra to get the shortest path between two nodes, so that it can be compared to A*. A square board is randomly generated and a few blocks are places to add complexity to the paths. Two random places on the grid are marked as start and end points for the algorithms to navigate. The program shows The result of using both Dijsktra and A* pathfinding algorithms to find the shortest path between those points (if there are more than one, one is found at random). The top shows Dijkstra, the bottom shows A*. The number of ticks and nodes each algorithm visited is also displayed. The blue X represends the Start, the yellow X’s represents the path taken to get to the goal. The red x’s are the nodes that were unexplored by the algorithm, the white ones being all the nodes visited but not part of the path.]]></summary></entry></feed>